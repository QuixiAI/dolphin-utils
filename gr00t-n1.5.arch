action_head.action_decoder.layer[1-2].W,[32,1024,1024],F32
action_head.action_decoder.layer[1-2].b,[32,1024],F32
action_head.action_encoder.W[1-3].W,[32,32,1536],F32
action_head.action_encoder.W[1-3].b,[32,1536],F32
action_head.model.proj_out_[1-2],[3072,1536],F32
action_head.model.proj_out_[1-2].bias,[3072],F32
action_head.model.timestep_encoder.timestep_embedder.linear_[1-2],[1536,256],F32
action_head.model.timestep_encoder.timestep_embedder.linear_[1-2].bias,[1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_k,[1536,2048],F32
action_head.model.transformer_blocks.[0-15].attn1.to_k.bias,[1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_out.0,[1536,1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_out.0.bias,[1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_q,[1536,1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_q.bias,[1536],F32
action_head.model.transformer_blocks.[0-15].attn1.to_v,[1536,2048],F32
action_head.model.transformer_blocks.[0-15].attn1.to_v.bias,[1536],F32
action_head.model.transformer_blocks.[0-15].ff.net.0.proj,[6144,1536],F32
action_head.model.transformer_blocks.[0-15].ff.net.0.proj.bias,[6144],F32
action_head.model.transformer_blocks.[0-15].ff.net.2,[1536,6144],F32
action_head.model.transformer_blocks.[0-15].ff.net.2.bias,[1536],F32
action_head.model.transformer_blocks.[0-15].norm1.linear,[3072,1536],F32
action_head.model.transformer_blocks.[0-15].norm1.linear.bias,[3072],F32
action_head.position_embedding,[1024,1536],F32
action_head.state_encoder.layer[1-2].W,[32,64,1024],F32
action_head.state_encoder.layer[1-2].b,[32,1024],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_k,[2048,2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_k.bias,[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_out.0,[2048,2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_out.0.bias,[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_q,[2048,2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_q.bias,[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_v,[2048,2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].attn1.to_v.bias,[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].ff.net.0.proj,[8192,2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].ff.net.0.proj.bias,[8192],F32
action_head.vl_self_attention.transformer_blocks.[0-3].ff.net.2,[2048,8192],F32
action_head.vl_self_attention.transformer_blocks.[0-3].ff.net.2.bias,[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].norm[1, 3],[2048],F32
action_head.vl_self_attention.transformer_blocks.[0-3].norm[1, 3].bias,[2048],F32
action_head.vlln,[2048],F32
action_head.vlln.bias,[2048],F32
backbone.eagle_model.language_model.lm_head,[151680,2048],BF16
backbone.eagle_model.language_model.model.embed_tokens,[151680,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].input_layernorm,[2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].mlp.down_proj,[2048,6144],BF16
backbone.eagle_model.language_model.model.layers.[0-11].mlp.gate_proj,[6144,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].mlp.up_proj,[6144,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].post_attention_layernorm,[2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.k_norm,[128],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.k_proj,[1024,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.o_proj,[2048,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.q_norm,[128],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.q_proj,[2048,2048],BF16
backbone.eagle_model.language_model.model.layers.[0-11].self_attn.v_proj,[1024,2048],BF16
backbone.eagle_model.language_model.model.norm,[2048],BF16
backbone.eagle_model.mlp1.0,[2048,1152],BF16
backbone.eagle_model.mlp1.0.bias,[2048],BF16
backbone.eagle_model.vision_model.vision_model.embeddings.patch_embedding,[1152,3,14,14],BF16
backbone.eagle_model.vision_model.vision_model.embeddings.patch_embedding.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.embeddings.position_embedding,[256,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].layer_norm[1-2],[1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].layer_norm[1-2].bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].mlp.fc[1-2],[4304,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].mlp.fc[1-2].bias,[4304],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.k_proj,[1152,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.k_proj.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.out_proj,[1152,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.out_proj.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.q_proj,[1152,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.q_proj.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.v_proj,[1152,1152],BF16
backbone.eagle_model.vision_model.vision_model.encoder.layers.[0-26].self_attn.v_proj.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.head.attention.in_proj_bias,[3456],BF16
backbone.eagle_model.vision_model.vision_model.head.attention.in_proj_weight,[3456,1152],BF16
backbone.eagle_model.vision_model.vision_model.head.attention.out_proj,[1152,1152],BF16
backbone.eagle_model.vision_model.vision_model.head.attention.out_proj.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.head.layernorm,[1152],BF16
backbone.eagle_model.vision_model.vision_model.head.layernorm.bias,[1152],BF16
backbone.eagle_model.vision_model.vision_model.head.mlp.fc[1-2],[4304,1152],BF16
backbone.eagle_model.vision_model.vision_model.head.mlp.fc[1-2].bias,[4304],BF16
backbone.eagle_model.vision_model.vision_model.head.probe,[1,1,1152],BF16
backbone.eagle_model.vision_model.vision_model.post_layernorm,[1152],BF16
backbone.eagle_model.vision_model.vision_model.post_layernorm.bias,[1152],BF16

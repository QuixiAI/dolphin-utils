lm_head,[152064,3584],BF16
model.embed_tokens,[152064,3584],BF16
model.layers.[0-27].input_layernorm,[3584],BF16
model.layers.[0-27].mlp.down_proj,[3584,18944],BF16
model.layers.[0-27].mlp.gate_proj,[18944,3584],BF16
model.layers.[0-27].mlp.up_proj,[18944,3584],BF16
model.layers.[0-27].post_attention_layernorm,[3584],BF16
model.layers.[0-27].self_attn.k_proj,[512,3584],BF16
model.layers.[0-27].self_attn.k_proj.bias,[512],BF16
model.layers.[0-27].self_attn.o_proj,[3584,3584],BF16
model.layers.[0-27].self_attn.q_proj,[3584,3584],BF16
model.layers.[0-27].self_attn.q_proj.bias,[3584],BF16
model.layers.[0-27].self_attn.v_proj,[512,3584],BF16
model.layers.[0-27].self_attn.v_proj.bias,[512],BF16
model.norm,[3584],BF16
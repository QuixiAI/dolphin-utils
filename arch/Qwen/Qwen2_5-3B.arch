model.embed_tokens,[151936,2048],BF16%
model.layers.[0-35].input_layernorm,[2048],BF16
model.layers.[0-35].mlp.down_proj,[2048,11008],BF16
model.layers.[0-35].mlp.gate_proj,[11008,2048],BF16
model.layers.[0-35].mlp.up_proj,[11008,2048],BF16
model.layers.[0-35].post_attention_layernorm,[2048],BF16
model.layers.[0-35].self_attn.k_proj,[256,2048],BF16
model.layers.[0-35].self_attn.k_proj.bias,[256],BF16
model.layers.[0-35].self_attn.o_proj,[2048,2048],BF16
model.layers.[0-35].self_attn.q_proj,[2048,2048],BF16
model.layers.[0-35].self_attn.q_proj.bias,[2048],BF16
model.layers.[0-35].self_attn.v_proj,[256,2048],BF16
model.layers.[0-35].self_attn.v_proj.bias,[256],BF16
model.norm,[2048],BF16
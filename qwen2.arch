Qwen/Qwen2.5-0.5B
model.embed_tokens,[151936,896],BF16
model.layers.[0-23].input_layernorm,[896],BF16
model.layers.[0-23].mlp.down_proj,[896,4864],BF16
model.layers.[0-23].mlp.gate_proj,[4864,896],BF16
model.layers.[0-23].mlp.up_proj,[4864,896],BF16
model.layers.[0-23].post_attention_layernorm,[896],BF16
model.layers.[0-23].self_attn.k_proj,[128,896],BF16
model.layers.[0-23].self_attn.k_proj.bias,[128],BF16
model.layers.[0-23].self_attn.o_proj,[896,896],BF16
model.layers.[0-23].self_attn.q_proj,[896,896],BF16
model.layers.[0-23].self_attn.q_proj.bias,[896],BF16
model.layers.[0-23].self_attn.v_proj,[128,896],BF16
model.layers.[0-23].self_attn.v_proj.bias,[128],BF16
model.norm,[896],BF16

Qwen/Qwen2.5-1.5B
model.embed_tokens,[151936,1536],BF16
model.layers.[0-27].input_layernorm,[1536],BF16
model.layers.[0-27].mlp.down_proj,[1536,8960],BF16
model.layers.[0-27].mlp.gate_proj,[8960,1536],BF16
model.layers.[0-27].mlp.up_proj,[8960,1536],BF16
model.layers.[0-27].post_attention_layernorm,[1536],BF16
model.layers.[0-27].self_attn.k_proj,[256,1536],BF16
model.layers.[0-27].self_attn.k_proj.bias,[256],BF16
model.layers.[0-27].self_attn.o_proj,[1536,1536],BF16
model.layers.[0-27].self_attn.q_proj,[1536,1536],BF16
model.layers.[0-27].self_attn.q_proj.bias,[1536],BF16
model.layers.[0-27].self_attn.v_proj,[256,1536],BF16
model.layers.[0-27].self_attn.v_proj.bias,[256],BF16
model.norm,[1536],BF16

Qwen/Qwen2.5-3B
model.embed_tokens,[151936,2048],BF16%
model.layers.[0-35].input_layernorm,[2048],BF16
model.layers.[0-35].mlp.down_proj,[2048,11008],BF16
model.layers.[0-35].mlp.gate_proj,[11008,2048],BF16
model.layers.[0-35].mlp.up_proj,[11008,2048],BF16
model.layers.[0-35].post_attention_layernorm,[2048],BF16
model.layers.[0-35].self_attn.k_proj,[256,2048],BF16
model.layers.[0-35].self_attn.k_proj.bias,[256],BF16
model.layers.[0-35].self_attn.o_proj,[2048,2048],BF16
model.layers.[0-35].self_attn.q_proj,[2048,2048],BF16
model.layers.[0-35].self_attn.q_proj.bias,[2048],BF16
model.layers.[0-35].self_attn.v_proj,[256,2048],BF16
model.layers.[0-35].self_attn.v_proj.bias,[256],BF16
model.norm,[2048],BF16

Qwen/Qwen2.5-7B
lm_head,[152064,3584],BF16
model.embed_tokens,[152064,3584],BF16
model.layers.[0-27].input_layernorm,[3584],BF16
model.layers.[0-27].mlp.down_proj,[3584,18944],BF16
model.layers.[0-27].mlp.gate_proj,[18944,3584],BF16
model.layers.[0-27].mlp.up_proj,[18944,3584],BF16
model.layers.[0-27].post_attention_layernorm,[3584],BF16
model.layers.[0-27].self_attn.k_proj,[512,3584],BF16
model.layers.[0-27].self_attn.k_proj.bias,[512],BF16
model.layers.[0-27].self_attn.o_proj,[3584,3584],BF16
model.layers.[0-27].self_attn.q_proj,[3584,3584],BF16
model.layers.[0-27].self_attn.q_proj.bias,[3584],BF16
model.layers.[0-27].self_attn.v_proj,[512,3584],BF16
model.layers.[0-27].self_attn.v_proj.bias,[512],BF16
model.norm,[3584],BF16

Qwen/Qwen2.5-14B
lm_head,[152064,5120],BF16
model.embed_tokens,[152064,5120],BF16
model.layers.[0-47].input_layernorm,[5120],BF16
model.layers.[0-47].mlp.down_proj,[5120,13824],BF16
model.layers.[0-47].mlp.gate_proj,[13824,5120],BF16
model.layers.[0-47].mlp.up_proj,[13824,5120],BF16
model.layers.[0-47].post_attention_layernorm,[5120],BF16
model.layers.[0-47].self_attn.k_proj,[1024,5120],BF16
model.layers.[0-47].self_attn.k_proj.bias,[1024],BF16
model.layers.[0-47].self_attn.o_proj,[5120,5120],BF16
model.layers.[0-47].self_attn.q_proj,[5120,5120],BF16
model.layers.[0-47].self_attn.q_proj.bias,[5120],BF16
model.layers.[0-47].self_attn.v_proj,[1024,5120],BF16
model.layers.[0-47].self_attn.v_proj.bias,[1024],BF16
model.norm,[5120],BF16

Qwen/Qwen2.5-32B
lm_head,[152064,5120],BF16
model.embed_tokens,[152064,5120],BF16%
model.layers.[0-63].input_layernorm,[5120],BF16
model.layers.[0-63].mlp.down_proj,[5120,27648],BF16
model.layers.[0-63].mlp.gate_proj,[27648,5120],BF16
model.layers.[0-63].mlp.up_proj,[27648,5120],BF16
model.layers.[0-63].post_attention_layernorm,[5120],BF16
model.layers.[0-63].self_attn.k_proj,[1024,5120],BF16
model.layers.[0-63].self_attn.k_proj.bias,[1024],BF16
model.layers.[0-63].self_attn.o_proj,[5120,5120],BF16
model.layers.[0-63].self_attn.q_proj,[5120,5120],BF16
model.layers.[0-63].self_attn.q_proj.bias,[5120],BF16
model.layers.[0-63].self_attn.v_proj,[1024,5120],BF16
model.layers.[0-63].self_attn.v_proj.bias,[1024],BF16
model.norm,[5120],BF16

Qwen/Qwen2.5-72B
lm_head,[152064,8192],BF16
model.embed_tokens,[152064,8192],BF16
model.layers.[0-79].input_layernorm,[8192],BF16
model.layers.[0-79].mlp.down_proj,[8192,29568],BF16
model.layers.[0-79].mlp.gate_proj,[29568,8192],BF16
model.layers.[0-79].mlp.up_proj,[29568,8192],BF16
model.layers.[0-79].post_attention_layernorm,[8192],BF16
model.layers.[0-79].self_attn.k_proj,[1024,8192],BF16
model.layers.[0-79].self_attn.k_proj.bias,[1024],BF16
model.layers.[0-79].self_attn.o_proj,[8192,8192],BF16
model.layers.[0-79].self_attn.q_proj,[8192,8192],BF16
model.layers.[0-79].self_attn.q_proj.bias,[8192],BF16
model.layers.[0-79].self_attn.v_proj,[1024,8192],BF16
model.layers.[0-79].self_attn.v_proj.bias,[1024],BF16
model.norm,[8192],BF16
